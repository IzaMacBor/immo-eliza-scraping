{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/nieuwpoort/8620/8408140\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/fraire/5650/8502446\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/st-amand/6221/8626490\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/appartement/te-koop/wemmel/1780/8710246\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/gosselies/6041/8867934\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/huissignies/7950/8911235\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/courcelles/6180/8991042\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/appartement/te-koop/leuven/3000/9029421\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/montigny-le-tilleul/6110/9064184\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/appartement/te-koop/bruxelles-21/1210/9213967\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/tielt-8700/8700/9315703\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/charleroi/6000/9359489\n",
      "Failed to retrieve HTML for https://www.immoweb.be/nl/zoekertje/huis/te-koop/charleroi/6000/9445032\n",
      "Scraping completed. Data saved to 'property_details.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get HTML content from a URL\n",
    "def get_html(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text if response.status_code == 200 else None\n",
    "\n",
    "# Function to scrape property details from HTML\n",
    "    \n",
    "def property_details(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    s = BeautifulSoup(features=\"lxml\")\n",
    "    details = {}\n",
    "\n",
    "    property_id_element = soup.find('div', class_=\"classified__header--immoweb-code\")\n",
    "    details['Immoweb Code'] = property_id_element.text.strip() if property_id_element else None\n",
    "\n",
    "    locality_element = soup.find(\"div\", class_=\"classified__information--address\", attrs={\"aria-hidden\": \"true\"})\n",
    "    details['Locality'] = locality_element.get_text(strip=True) if locality_element else None\n",
    "\n",
    "    postal_code_element = soup.find('span', class_=\"classified__information--address-row\")\n",
    "    details['Postal code'] = postal_code_element.text.strip() if postal_code_element else None\n",
    "\n",
    "    price_element = s.find('span', class_=\"sr-only\")\n",
    "    details['Price'] = price_element.text.strip() if price_element else None\n",
    "\n",
    "    type_of_property_element = soup.find()\n",
    "    details['Type of property'] = type_of_property_element.text.strip() if type_of_property_element None\n",
    "    \n",
    "    subtype_of_property_element = soup.find()\n",
    "    details['Subtype of property'] = subtype_of_property_element.text.strip() if subtype_of_property_element None\n",
    "\n",
    "    type_of_sale_element = soup.find()\n",
    "    details['Type of sale'] = type_of_sale_element.text.strip() if type_of_sale_element else None\n",
    "\n",
    "    rooms_number_element = soup.find('span', class_=\"overview__text\")\n",
    "    details['Number of rooms'] = rooms_number_element.text.strip() if rooms_number_element else None\n",
    "\n",
    "    living_area_element = soup.find('p', class_=\"classified__information\", attrs={\"aria-hidden\": \"true\"})\n",
    "    details['Living area'] = living_area_element.text.strip() if living_area_element else None\n",
    "\n",
    "    kitchen_element = soup.find('tr', class_=\"classified-table__row\")\n",
    "    details['Equipped kitchen'] = kitchen_element.text.strip() if kitchen_element else None\n",
    "\n",
    "    furnished_element = soup.find()\n",
    "    details['Furnished'] = furnished_element.text.strip() if furnished_element else None\n",
    "\n",
    "    open_fire_element = soup.find()\n",
    "    details['Open fire'] = open_fire_element.text.strip() if open_fire_element else None\n",
    "\n",
    "    terrace_element = soup.find()\n",
    "    details['Terrace'] = terrace_element.text.strip() if terrace_element else None\n",
    "\n",
    "    garden_element = soup.find()\n",
    "    details['Garden'] = garden_element.text.strip() if garden_element else None\n",
    "\n",
    "    facades_element = soup.find()\n",
    "    details['Number of facades'] = facades_element.text.strip() if facades_element else None\n",
    "\n",
    "    swimming_pool_element = soup.find()\n",
    "    details['Swimming pool'] = swimming_pool_element.text.strip() if swimming_pool_element else None\n",
    "\n",
    "    state_element = soup.find()\n",
    "    details['State of building'] = state_element.text.strip() if state_element else None\n",
    "    \n",
    "\n",
    "    return details\n",
    "\n",
    "# Load URLs from the CSV file\n",
    "url_file_path = r\"C:\\Users\\izama\\Desktop\\repo\\immo-eliza-scraping\\xml_files\\filters.csv\"\n",
    "urls_df = pd.read_csv(url_file_path)\n",
    "\n",
    "# Assume the URLs are in a column named 'url'\n",
    "urls = urls_df['url'].head(10000).tolist()  # Get only the first 10 URLs\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through each URL and scrape the data\n",
    "for url in urls:\n",
    "    html = get_html(url)\n",
    "    if html:\n",
    "        details = property_details(html)\n",
    "        results.append(details)  # Append the details to the results list\n",
    "    else:\n",
    "        print(f\"Failed to retrieve HTML for {url}\")\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('property_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'property_details.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
